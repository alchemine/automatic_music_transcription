{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Create a MIDI file\n",
    "from midiutil import MIDIFile\n",
    "\n",
    "SOUNDFONT_PATH = \"/Users/dj.yoon/.fluidsynth/soundfont.sf2\"\n",
    "DATA_PATH = \"dataset\"\n",
    "\n",
    "\n",
    "def generate_dataset(random_seed, n_datas, n_max_instruments, sampling_rate):\n",
    "    \"\"\"\n",
    "    Generates a dataset of mixed audio WAV files and their corresponding separated instrument WAV files.\n",
    "\n",
    "    Parameters:\n",
    "    - random_seed (int): Seed for random number generation.\n",
    "    - n_datas (int): Number of data samples to generate.\n",
    "    - n_max_instruments (int): Maximum number of instruments in a mix.\n",
    "    - sampling_rate (int): Sampling rate for audio files.\n",
    "\n",
    "    The function creates a 'mixed' directory containing the mixed audio files and an 'instruments' directory\n",
    "    containing subdirectories for each data sample with the individual instrument audio files.\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Path to the SoundFont\n",
    "    sf2_path = SOUNDFONT_PATH\n",
    "\n",
    "    # Ensure the SoundFont file exists\n",
    "    if not os.path.isfile(sf2_path):\n",
    "        raise FileNotFoundError(f\"SoundFont file not found at {sf2_path}\")\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(\"temp_midis\", exist_ok=True)\n",
    "\n",
    "    # List of available instruments (program numbers)\n",
    "    instruments_list = list(range(0, 128))  # General MIDI instruments\n",
    "\n",
    "    for i in range(n_datas):\n",
    "        n_instruments = random.randint(1, n_max_instruments)\n",
    "        selected_instruments = random.sample(instruments_list, n_instruments)\n",
    "\n",
    "        print(\n",
    "            f\"Generating data sample {i+1}/{n_datas} with {n_instruments} instruments.\"\n",
    "        )\n",
    "\n",
    "        # For each instrument, generate a MIDI file with random notes\n",
    "        duration = 4  # seconds\n",
    "        tempo = 120  # BPM\n",
    "        instrument_audios = []\n",
    "\n",
    "        for idx, instrument in enumerate(selected_instruments):\n",
    "            midi = MIDIFile(1)\n",
    "            track = 0\n",
    "            time = 0  # In beats\n",
    "            midi.addTrackName(track, time, f\"Instrument_{instrument}\")\n",
    "            midi.addTempo(track, time, tempo)\n",
    "\n",
    "            # Set the instrument\n",
    "            channel = 0  # Use channel 0 for all instruments\n",
    "            midi.addProgramChange(track, channel, time, instrument)\n",
    "\n",
    "            # Generate random notes\n",
    "            num_notes = 8\n",
    "            notes = np.random.randint(60, 72, size=num_notes)  # C4 to B4\n",
    "            note_duration = duration / num_notes / (60 / tempo)  # duration in beats\n",
    "\n",
    "            for note in notes:\n",
    "                midi.addNote(track, channel, note, time, note_duration, 100)\n",
    "                time += note_duration\n",
    "\n",
    "            # Save the MIDI file\n",
    "            midi_path = f\"temp_midis/data_{i}_instrument_{idx}.mid\"\n",
    "            with open(midi_path, \"wb\") as midi_file:\n",
    "                midi.writeFile(midi_file)\n",
    "\n",
    "            # Use fluidsynth to render MIDI to WAV\n",
    "            instrument_dir = os.path.join(DATA_PATH, \"instruments\", f\"data_{i}\")\n",
    "            os.makedirs(instrument_dir, exist_ok=True)\n",
    "            instrument_wav_path = os.path.join(instrument_dir, f\"instrument_{idx}.wav\")\n",
    "\n",
    "            cmd = [\n",
    "                \"fluidsynth\",\n",
    "                \"-ni\",  # No interactive mode\n",
    "                \"-F\",\n",
    "                instrument_wav_path,\n",
    "                \"-r\",\n",
    "                str(sampling_rate),\n",
    "                sf2_path,\n",
    "                midi_path,\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True)\n",
    "\n",
    "            # Load the WAV file data\n",
    "            with wave.open(instrument_wav_path, \"rb\") as wav_file:\n",
    "                n_channels = wav_file.getnchannels()\n",
    "                sample_width = wav_file.getsampwidth()\n",
    "                n_frames = wav_file.getnframes()\n",
    "                frames = wav_file.readframes(n_frames)\n",
    "                audio_data = np.frombuffer(frames, dtype=np.int16)\n",
    "                instrument_audios.append(audio_data)\n",
    "\n",
    "        # Mix the audio tracks\n",
    "        # Ensure all audio tracks are the same length\n",
    "        min_length = min([len(a) for a in instrument_audios])\n",
    "        instrument_audios = [a[:min_length] for a in instrument_audios]\n",
    "\n",
    "        mixed_audio = np.sum(instrument_audios, axis=0)\n",
    "        # Normalize mixed_audio\n",
    "        max_val = np.max(np.abs(mixed_audio))\n",
    "        if max_val > 0:\n",
    "            mixed_audio = mixed_audio / max_val * 32767 * 0.9  # avoid clipping\n",
    "        mixed_audio = np.int16(mixed_audio)\n",
    "\n",
    "        # Save mixed audio\n",
    "        mixed_wav_path = os.path.join(DATA_PATH, \"mixed\", f\"data_{i}.wav\")\n",
    "        os.makedirs(os.path.dirname(mixed_wav_path), exist_ok=True)\n",
    "        with wave.open(mixed_wav_path, \"w\") as wav_file:\n",
    "            wav_file.setnchannels(n_channels)\n",
    "            wav_file.setsampwidth(sample_width)\n",
    "            wav_file.setframerate(sampling_rate)\n",
    "            wav_file.writeframes(mixed_audio.tobytes())\n",
    "\n",
    "    # Clean up temporary MIDI files\n",
    "    shutil.rmtree(\"temp_midis\")\n",
    "\n",
    "    print(\"Dataset generation completed.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "generate_dataset(random_seed=42, n_datas=1, n_max_instruments=3, sampling_rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/amt/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "Setting parameter 'synth.release-time' not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data sample 1/1 with 3 instruments.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['fluidsynth', '-ni', '-R', '0', '-C', '0', '-o', 'synth.release-time=0.1', '-F', 'dataset/instruments/data_0/instrument_0.wav', '-r', '44100', '/Users/dj.yoon/.fluidsynth/soundfont.sf2', 'temp_midis/data_0_instrument_0.mid']' returned non-zero exit status 255.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 185\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset generation completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_max_instruments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m44100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 121\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(random_seed, n_datas, n_max_instruments, sampling_rate)\u001b[0m\n\u001b[1;32m    103\u001b[0m instrument_wav_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(instrument_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstrument_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfluidsynth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-ni\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     midi_path,\n\u001b[1;32m    120\u001b[0m ]\n\u001b[0;32m--> 121\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Load the WAV file data\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wave\u001b[38;5;241m.\u001b[39mopen(instrument_wav_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m wav_file:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/amt/lib/python3.12/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['fluidsynth', '-ni', '-R', '0', '-C', '0', '-o', 'synth.release-time=0.1', '-F', 'dataset/instruments/data_0/instrument_0.wav', '-r', '44100', '/Users/dj.yoon/.fluidsynth/soundfont.sf2', 'temp_midis/data_0_instrument_0.mid']' returned non-zero exit status 255."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import shutil\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Create a MIDI file\n",
    "from midiutil import MIDIFile\n",
    "\n",
    "SOUNDFONT_PATH = \"/Users/dj.yoon/.fluidsynth/soundfont.sf2\"\n",
    "DATA_PATH = \"dataset\"\n",
    "\n",
    "\n",
    "def mix_wav_files(wav_files, output_file):\n",
    "    mix = None\n",
    "    for wav_file in wav_files:\n",
    "        audio = AudioSegment.from_wav(wav_file)\n",
    "        if mix is None:\n",
    "            mix = audio\n",
    "        else:\n",
    "            mix = mix.overlay(audio)\n",
    "\n",
    "    mix.export(output_file, format=\"wav\")\n",
    "\n",
    "\n",
    "def generate_dataset(random_seed, n_datas, n_max_instruments, sampling_rate):\n",
    "    \"\"\"\n",
    "    Generates a dataset of mixed audio WAV files and their corresponding separated instrument WAV files.\n",
    "\n",
    "    Parameters:\n",
    "    - random_seed (int): Seed for random number generation.\n",
    "    - n_datas (int): Number of data samples to generate.\n",
    "    - n_max_instruments (int): Maximum number of instruments in a mix.\n",
    "    - sampling_rate (int): Sampling rate for audio files.\n",
    "\n",
    "    The function creates a 'mixed' directory containing the mixed audio files and an 'instruments' directory\n",
    "    containing subdirectories for each data sample with the individual instrument audio files.\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Path to the SoundFont\n",
    "    sf2_path = SOUNDFONT_PATH\n",
    "\n",
    "    # Ensure the SoundFont file exists\n",
    "    if not os.path.isfile(sf2_path):\n",
    "        raise FileNotFoundError(f\"SoundFont file not found at {sf2_path}\")\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(\"temp_midis\", exist_ok=True)\n",
    "\n",
    "    # List of available instruments (program numbers)\n",
    "    instruments_list = list(range(0, 128))  # General MIDI instruments\n",
    "\n",
    "    for i in range(n_datas):\n",
    "        n_instruments = random.randint(1, n_max_instruments)\n",
    "        selected_instruments = random.sample(instruments_list, n_instruments)\n",
    "\n",
    "        print(\n",
    "            f\"Generating data sample {i+1}/{n_datas} with {n_instruments} instruments.\"\n",
    "        )\n",
    "\n",
    "        # For each instrument, generate a MIDI file with random notes\n",
    "        duration = 4  # seconds\n",
    "        tempo = 120  # BPM\n",
    "        duration_in_beats = duration * tempo / 60  # Total duration in beats\n",
    "        num_notes = 8\n",
    "        note_duration = duration_in_beats / num_notes  # duration in beats\n",
    "        instrument_audios = []\n",
    "\n",
    "        inst_wav_files = []\n",
    "        for idx, instrument in enumerate(selected_instruments):\n",
    "            midi = MIDIFile(1)\n",
    "            track = 0\n",
    "            midi.addTrackName(track, 0, f\"Instrument_{instrument}\")\n",
    "            midi.addTempo(track, 0, tempo)\n",
    "\n",
    "            # Set the instrument\n",
    "            channel = 0  # Use channel 0 for all instruments\n",
    "            midi.addProgramChange(track, channel, 0, instrument)\n",
    "\n",
    "            # Generate random notes\n",
    "            notes = np.random.randint(60, 72, size=num_notes)  # C4 to B4\n",
    "            note_times = np.arange(0, duration_in_beats, note_duration)\n",
    "\n",
    "            for note, time in zip(notes, note_times):\n",
    "                midi.addNote(track, channel, note, time, note_duration, 100)\n",
    "\n",
    "            # Add All Sound Off controller message at the exact end time\n",
    "            midi.addControllerEvent(track, channel, duration_in_beats, 120, 0)\n",
    "\n",
    "            # Save the MIDI file\n",
    "            midi_path = f\"temp_midis/data_{i}_instrument_{idx}.mid\"\n",
    "            with open(midi_path, \"wb\") as midi_file:\n",
    "                midi.writeFile(midi_file)\n",
    "\n",
    "            # Use fluidsynth to render MIDI to WAV\n",
    "            instrument_dir = os.path.join(DATA_PATH, \"instruments\", f\"data_{i}\")\n",
    "            os.makedirs(instrument_dir, exist_ok=True)\n",
    "            instrument_wav_path = os.path.join(instrument_dir, f\"instrument_{idx}.wav\")\n",
    "\n",
    "            cmd = [\n",
    "                \"fluidsynth\",\n",
    "                \"-ni\",\n",
    "                \"-R\",\n",
    "                \"0\",  # Disable reverb\n",
    "                \"-C\",\n",
    "                \"0\",  # Disable chorus\n",
    "                \"-o\",\n",
    "                \"synth.release-time=0.1\",  # Short release time\n",
    "                \"-F\",\n",
    "                instrument_wav_path,\n",
    "                \"-r\",\n",
    "                str(sampling_rate),\n",
    "                sf2_path,\n",
    "                midi_path,\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True)\n",
    "\n",
    "            # Load the WAV file data\n",
    "            with wave.open(instrument_wav_path, \"rb\") as wav_file:\n",
    "                n_channels = wav_file.getnchannels()\n",
    "                sample_width = wav_file.getsampwidth()\n",
    "                frames = wav_file.readframes(wav_file.getnframes())\n",
    "                audio_data = np.frombuffer(frames, dtype=np.int16)\n",
    "\n",
    "                # If stereo, convert to mono\n",
    "                if n_channels > 1:\n",
    "                    audio_data = audio_data.reshape(-1, n_channels)\n",
    "                    audio_data = audio_data.mean(axis=1).astype(np.int16)\n",
    "                    n_channels = 1  # Now mono\n",
    "\n",
    "                # Ensure the audio data has the exact expected length\n",
    "                expected_length = int(duration * sampling_rate)\n",
    "                current_length = len(audio_data)\n",
    "                if current_length < expected_length:\n",
    "                    # Pad with zeros\n",
    "                    audio_data = np.pad(\n",
    "                        audio_data,\n",
    "                        (0, expected_length - current_length),\n",
    "                        mode=\"constant\",\n",
    "                    )\n",
    "                elif current_length > expected_length:\n",
    "                    # Truncate to the expected length\n",
    "                    audio_data = audio_data[:expected_length]\n",
    "\n",
    "                instrument_audios.append(audio_data)\n",
    "            inst_wav_files.append(instrument_wav_path)\n",
    "\n",
    "        # # Mix the audio tracks\n",
    "        # # All audio tracks now have the same length\n",
    "        # instrument_audios = np.array(instrument_audios)\n",
    "\n",
    "        # mixed_audio = np.sum(instrument_audios, axis=0)\n",
    "        # # Normalize mixed_audio\n",
    "        # max_val = np.max(np.abs(mixed_audio))\n",
    "        # if max_val > 0:\n",
    "        #     mixed_audio = mixed_audio / max_val * 32767 * 0.9  # avoid clipping\n",
    "        # mixed_audio = np.int16(mixed_audio)\n",
    "\n",
    "        # # Save mixed audio\n",
    "        mixed_wav_path = os.path.join(DATA_PATH, \"mixed\", f\"data_{i}.wav\")\n",
    "        os.makedirs(os.path.dirname(mixed_wav_path), exist_ok=True)\n",
    "        # with wave.open(mixed_wav_path, \"w\") as wav_file:\n",
    "        #     wav_file.setnchannels(1)  # Mono\n",
    "        #     wav_file.setsampwidth(2)  # 2 bytes for np.int16\n",
    "        #     wav_file.setframerate(sampling_rate)\n",
    "        #     wav_file.writeframes(mixed_audio.tobytes())\n",
    "\n",
    "        mix_wav_files(\n",
    "            inst_wav_files,\n",
    "            mixed_wav_path,\n",
    "        )\n",
    "\n",
    "    # Clean up temporary MIDI files\n",
    "    shutil.rmtree(\"temp_midis\")\n",
    "\n",
    "    print(\"Dataset generation completed.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "generate_dataset(random_seed=42, n_datas=1, n_max_instruments=3, sampling_rate=44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
